model:
  name: "meta-llama/Llama-3.2-1B-Instruct"

training_data:
  name: "openai/gsm8k"
  subset: "main"
  split: "train"

training:
  learning_rate: 0.001
  epochs:        50
  optimizer:     "adam"
